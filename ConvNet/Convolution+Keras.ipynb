{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks: Application 2\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Implement a fully functioning ConvNet using Keras \n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Build and train a ConvNet in Keras with TensorFlow backend for a classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 - Keras model\n",
    "\n",
    "Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call. \n",
    "\n",
    "For more information on Keras, please refer the *TensorFlow Tutorial* or https://www.tensorflow.org/tutorials/\n",
    "\n",
    "### As usual, we will start by loading in the packages. \n",
    "\n",
    "As you can see, there are 2 important components in Keras library which are *keras.model* and *keras.layers* \n",
    "\n",
    "You don't need to import *TensorFlow* library because Keras will autoimatically add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from cnn_utils import *\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D, Flatten, Activation, Dense\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 - Loading Dataset\n",
    "\n",
    "Nothing special..same as previous excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "print(\"Show classes: \", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 77\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n",
    "\n",
    "In Keras, there are built-in functions that carry out the convolution steps for you.\n",
    "\n",
    "- **Conv2d(filters, kernel_size, strides = (1,1), input_shape = (h, w), padding = 'same'):**. **filter** is an integer, the dimensionality of the output space. **kernel_size** An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. **strides:** An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. **padding:** one of \"valid\" or \"same\" (case-insensitive), in this case we use \"same\". When using this layer as the first layer in a model, provide the keyword argument **input_shape** (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in  data_format=\"channels_last\".  You can read the full documentation on *Conv2D* [here](https://keras.io/layers/convolutional/#conv2d)\n",
    "\n",
    "\n",
    "- **Activation(activation):** In this excercise, we will use **relu**. You can read the full documentation on Activation [here](https://keras.io/activations/)\n",
    "\n",
    "\n",
    "- **MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'):** **pool_size:** integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). **strides:** Integer, tuple of 2 integers, or None. Strides values. If None, it will default to **pool_size**. You can read the full documentation on MaxPooling2D [here.](https://keras.io/layers/pooling/#maxpooling2d)\n",
    "\n",
    "\n",
    "- **Flatten():** Flattens the input. Does not affect the batch size. You can read the full documentation [here.](https://keras.io/layers/core/#flatten)\n",
    "\n",
    "\n",
    "- **Dense(units, activation):** Just your regular densely-connected NN layer. **units:** Positive integer, dimensionality of the output space. **activation:** Activation function to use (see activations). If you don't specify anything, no activation is applied. You can read the full documentation [here.](https://keras.io/layers/core/#activation)\n",
    "\n",
    "The model is same as from the previous excercise. To make it more clear, we separate the convolution layer into boxes.\n",
    "\n",
    "\n",
    "<img src=\"images/box.jpg\" style=\"width:800px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet (X, Y, Xtest, Ytest, epoch):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- training set, of shape (None, 64, 64, 3)\n",
    "    Y -- test set, of shape (None, n_y = 6)\n",
    "    Xtest -- training set, of shape (None, 64, 64, 3)\n",
    "    Ytest -- test set, of shape (None, n_y = 6)\n",
    "    epoch -- number of epochs of the optimization loop\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    model -- a Sequential object that return training accuracy, training loss, validation accuracy and validation loss\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    model = None #Sequential() model\n",
    "    \n",
    "    #Block 1\n",
    "    ### START CODE HERE ### (3 line of code)\n",
    "    None #Conv2D with no. of filters 8, kernel size (4,4), and padding SAME \n",
    "    None #Relu\n",
    "    None #MaxPooling2D with pool_size (8,8), strides 8, and padding SAME\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #Block 2\n",
    "    ### START CODE HERE ### (3 line of code)\n",
    "    None #Conv2D with no. of filters 16, kernel size (2,2), and padding SAME\n",
    "    None #Relu\n",
    "    None #MaxPooling2D with pool_size (4,4), strides 4, and padding SAME\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #Flatten and softmax classifier\n",
    "    ### START CODE HERE ### (2 line of code)\n",
    "    None #Flatten\n",
    "    None #Dense layer with output 6, and activation SOFTMAX\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #Compile model\n",
    "    model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs = epoch, validation_data = (Xtest, Ytest))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = convnet(X_train, Y_train,X_test, Y_test, epoch = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**: although it may not match perfectly, your expected output should be close to ours and your cost value should decrease.\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "    <td> \n",
    "    **Train Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.8917\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    **Test Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.8250\n",
    "    </td> \n",
    "</tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show your model layers and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have finised the assignment and built a model that recognizes SIGN language with more 80% accuracy on the test set. If you wish, feel free to play around with this dataset further and the hyper parameters.\n",
    "\n",
    "One thing that you can see here is, Keras is more straight forward and less hassle compare to Tensorflow. Maybe it loss some flexibility in coding such as setting the *initial weights* as Tensorflow have. I think, its not a big deal.\n",
    "\n",
    "Why I choose Keras? \n",
    "\n",
    "## \"Anda fikir saya ada masa untuk sakit kepala?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

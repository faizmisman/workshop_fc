{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks: Application 2\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Implement a fully functioning ConvNet using Keras \n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Build and train a ConvNet in Keras with TensorFlow backend for a classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 - Keras model\n",
    "\n",
    "Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call. \n",
    "\n",
    "For more information on Keras, please refer the *TensorFlow Tutorial* or https://www.tensorflow.org/tutorials/\n",
    "\n",
    "### As usual, we will start by loading in the packages. \n",
    "\n",
    "As you can see, there are 2 important components in Keras library which are *keras.model* and *keras.layers* \n",
    "\n",
    "You don't need to import *TensorFlow* library because Keras will autoimatically add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from cnn_utils import *\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D, Flatten, Activation, Dense\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 - Loading Dataset\n",
    "\n",
    "Nothing special..same as previous excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show classes:  [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "print(\"Show classes: \", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHY4awhe+w1FD+MJ3OGoIX/gORw3x/wHk5LWNFO15owAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25d86eae6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 77\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n",
    "\n",
    "The model is same as from the previous excercise. To make it more clear, we separate the convolution process into boxes.\n",
    "\n",
    "\n",
    "<img src=\"images/box.jpg\" style=\"width:800px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet (X, Y, Xtest, Ytest, epoch):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- training set, of shape (None, 64, 64, 3)\n",
    "    Y -- test set, of shape (None, n_y = 6)\n",
    "    Xtest -- training set, of shape (None, 64, 64, 3)\n",
    "    Ytest -- test set, of shape (None, n_y = 6)\n",
    "    epoch -- number of epochs of the optimization loop\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    model -- a Sequential object that return training accuracy, training loss, validation accuracy and validation loss\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    model = Sequential() #Sequential model\n",
    "    \n",
    "    #Block 1\n",
    "    ### START CODE HERE ### (3 line of code)\n",
    "    model.add(Conv2D(8, (4, 4), input_shape = (64, 64, 3), padding='same')) #Conv2D with no. of filters 8, kernel size (4,4), and padding SAME \n",
    "    model.add(Activation('relu')) #Relu\n",
    "    model.add(MaxPooling2D(pool_size = (8, 8), strides=8,padding='same')) #MaxPooling2D with pool_size (8,8), strides 8, and padding SAME\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #Block 2\n",
    "    ### START CODE HERE ### (3 line of code)\n",
    "    model.add(Conv2D(16, (2, 2), padding='same')) #Conv2D with no. of filters 16, kernel size (2,2), and padding SAME\n",
    "    model.add(Activation('relu')) #Relu\n",
    "    model.add(MaxPooling2D(pool_size = (4, 4), strides=4,padding='same')) #MaxPooling2D with pool_size (4,4), strides 4, and padding SAME\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #Flatten and softmax classifier\n",
    "    ### START CODE HERE ### (2 line of code)\n",
    "    model.add(Flatten()) #Flatten\n",
    "    model.add(Dense(6, activation = 'softmax')) #Dense layer with output 6, and activation SOFTMAX\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #Compile model\n",
    "    model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs = epoch, validation_data = (Xtest, Ytest))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples, validate on 120 samples\n",
      "Epoch 1/100\n",
      "1080/1080 [==============================] - 3s 2ms/step - loss: 1.8342 - acc: 0.1694 - val_loss: 1.7936 - val_acc: 0.1500\n",
      "Epoch 2/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 1.7882 - acc: 0.1898 - val_loss: 1.7816 - val_acc: 0.1583\n",
      "Epoch 3/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 1.7729 - acc: 0.2324 - val_loss: 1.7639 - val_acc: 0.3667\n",
      "Epoch 4/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 1.7544 - acc: 0.2917 - val_loss: 1.7425 - val_acc: 0.3417\n",
      "Epoch 5/100\n",
      "1080/1080 [==============================] - 0s 258us/step - loss: 1.7351 - acc: 0.3056 - val_loss: 1.7188 - val_acc: 0.4167\n",
      "Epoch 6/100\n",
      "1080/1080 [==============================] - 0s 267us/step - loss: 1.7098 - acc: 0.3139 - val_loss: 1.6952 - val_acc: 0.3583\n",
      "Epoch 7/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 1.6739 - acc: 0.3694 - val_loss: 1.6448 - val_acc: 0.4333\n",
      "Epoch 8/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 1.6294 - acc: 0.4019 - val_loss: 1.6290 - val_acc: 0.3250\n",
      "Epoch 9/100\n",
      "1080/1080 [==============================] - 0s 266us/step - loss: 1.5744 - acc: 0.4148 - val_loss: 1.5473 - val_acc: 0.4500\n",
      "Epoch 10/100\n",
      "1080/1080 [==============================] - 0s 265us/step - loss: 1.5152 - acc: 0.4231 - val_loss: 1.5220 - val_acc: 0.4083\n",
      "Epoch 11/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 1.4645 - acc: 0.4852 - val_loss: 1.4708 - val_acc: 0.4417\n",
      "Epoch 12/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 1.3949 - acc: 0.5093 - val_loss: 1.3690 - val_acc: 0.5250\n",
      "Epoch 13/100\n",
      "1080/1080 [==============================] - 0s 266us/step - loss: 1.3246 - acc: 0.5250 - val_loss: 1.3165 - val_acc: 0.5333\n",
      "Epoch 14/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 1.2866 - acc: 0.5222 - val_loss: 1.2867 - val_acc: 0.5417\n",
      "Epoch 15/100\n",
      "1080/1080 [==============================] - 0s 271us/step - loss: 1.1772 - acc: 0.6296 - val_loss: 1.1933 - val_acc: 0.5583\n",
      "Epoch 16/100\n",
      "1080/1080 [==============================] - 0s 303us/step - loss: 1.1221 - acc: 0.6315 - val_loss: 1.1756 - val_acc: 0.5333\n",
      "Epoch 17/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 1.0658 - acc: 0.6593 - val_loss: 1.1220 - val_acc: 0.5750\n",
      "Epoch 18/100\n",
      "1080/1080 [==============================] - 0s 284us/step - loss: 1.0317 - acc: 0.6537 - val_loss: 1.0602 - val_acc: 0.6333\n",
      "Epoch 19/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 0.9818 - acc: 0.6722 - val_loss: 1.0398 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "1080/1080 [==============================] - 0s 303us/step - loss: 0.9629 - acc: 0.6917 - val_loss: 1.0275 - val_acc: 0.5500\n",
      "Epoch 21/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.9221 - acc: 0.6963 - val_loss: 0.9639 - val_acc: 0.6833\n",
      "Epoch 22/100\n",
      "1080/1080 [==============================] - 0s 272us/step - loss: 0.8813 - acc: 0.7157 - val_loss: 0.9495 - val_acc: 0.6333\n",
      "Epoch 23/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 0.8611 - acc: 0.7139 - val_loss: 0.9171 - val_acc: 0.6750\n",
      "Epoch 24/100\n",
      "1080/1080 [==============================] - 0s 272us/step - loss: 0.8330 - acc: 0.7241 - val_loss: 0.8764 - val_acc: 0.6750\n",
      "Epoch 25/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.8082 - acc: 0.7370 - val_loss: 0.8509 - val_acc: 0.6917\n",
      "Epoch 26/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.8034 - acc: 0.7194 - val_loss: 0.8788 - val_acc: 0.6750\n",
      "Epoch 27/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 0.7720 - acc: 0.7398 - val_loss: 0.8299 - val_acc: 0.6750\n",
      "Epoch 28/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.7617 - acc: 0.7537 - val_loss: 0.8035 - val_acc: 0.6750\n",
      "Epoch 29/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.7548 - acc: 0.7481 - val_loss: 0.7968 - val_acc: 0.7083\n",
      "Epoch 30/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 0.7305 - acc: 0.7500 - val_loss: 0.7686 - val_acc: 0.7167\n",
      "Epoch 31/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.7172 - acc: 0.7639 - val_loss: 0.7532 - val_acc: 0.7250\n",
      "Epoch 32/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 0.7048 - acc: 0.7583 - val_loss: 0.7592 - val_acc: 0.7083\n",
      "Epoch 33/100\n",
      "1080/1080 [==============================] - 0s 266us/step - loss: 0.6954 - acc: 0.7611 - val_loss: 0.7534 - val_acc: 0.7250\n",
      "Epoch 34/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.6867 - acc: 0.7639 - val_loss: 0.7565 - val_acc: 0.7167\n",
      "Epoch 35/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.7127 - acc: 0.7519 - val_loss: 0.7565 - val_acc: 0.7167\n",
      "Epoch 36/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 0.6784 - acc: 0.7694 - val_loss: 0.7160 - val_acc: 0.7417\n",
      "Epoch 37/100\n",
      "1080/1080 [==============================] - 0s 268us/step - loss: 0.6483 - acc: 0.7704 - val_loss: 0.7228 - val_acc: 0.7250\n",
      "Epoch 38/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.6426 - acc: 0.7778 - val_loss: 0.7115 - val_acc: 0.7583\n",
      "Epoch 39/100\n",
      "1080/1080 [==============================] - 0s 289us/step - loss: 0.6301 - acc: 0.7769 - val_loss: 0.6838 - val_acc: 0.7583\n",
      "Epoch 40/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.6102 - acc: 0.7944 - val_loss: 0.6827 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "1080/1080 [==============================] - 0s 281us/step - loss: 0.6168 - acc: 0.7972 - val_loss: 0.6821 - val_acc: 0.7250\n",
      "Epoch 42/100\n",
      "1080/1080 [==============================] - 0s 272us/step - loss: 0.6057 - acc: 0.7935 - val_loss: 0.6977 - val_acc: 0.7417\n",
      "Epoch 43/100\n",
      "1080/1080 [==============================] - 0s 298us/step - loss: 0.5913 - acc: 0.7981 - val_loss: 0.6647 - val_acc: 0.7083\n",
      "Epoch 44/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 0.6047 - acc: 0.7778 - val_loss: 0.6783 - val_acc: 0.7250\n",
      "Epoch 45/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.5993 - acc: 0.7944 - val_loss: 0.6724 - val_acc: 0.7250\n",
      "Epoch 46/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.5674 - acc: 0.8056 - val_loss: 0.6377 - val_acc: 0.7833\n",
      "Epoch 47/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.5738 - acc: 0.8009 - val_loss: 0.6343 - val_acc: 0.7417\n",
      "Epoch 48/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.5731 - acc: 0.7907 - val_loss: 0.6807 - val_acc: 0.6917\n",
      "Epoch 49/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 0.5954 - acc: 0.7741 - val_loss: 0.6575 - val_acc: 0.7167\n",
      "Epoch 50/100\n",
      "1080/1080 [==============================] - 0s 267us/step - loss: 0.5602 - acc: 0.8102 - val_loss: 0.6116 - val_acc: 0.7750\n",
      "Epoch 51/100\n",
      "1080/1080 [==============================] - 0s 266us/step - loss: 0.5363 - acc: 0.8194 - val_loss: 0.6124 - val_acc: 0.7833\n",
      "Epoch 52/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.5371 - acc: 0.8157 - val_loss: 0.6187 - val_acc: 0.8083\n",
      "Epoch 53/100\n",
      "1080/1080 [==============================] - 0s 265us/step - loss: 0.5166 - acc: 0.8343 - val_loss: 0.6014 - val_acc: 0.7833\n",
      "Epoch 54/100\n",
      "1080/1080 [==============================] - 0s 271us/step - loss: 0.5298 - acc: 0.8250 - val_loss: 0.6261 - val_acc: 0.7833\n",
      "Epoch 55/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.5219 - acc: 0.8213 - val_loss: 0.6213 - val_acc: 0.7750\n",
      "Epoch 56/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.5075 - acc: 0.8278 - val_loss: 0.6162 - val_acc: 0.7833\n",
      "Epoch 57/100\n",
      "1080/1080 [==============================] - 0s 270us/step - loss: 0.5034 - acc: 0.8324 - val_loss: 0.5837 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "1080/1080 [==============================] - 0s 267us/step - loss: 0.5007 - acc: 0.8343 - val_loss: 0.5900 - val_acc: 0.8083\n",
      "Epoch 59/100\n",
      "1080/1080 [==============================] - 0s 266us/step - loss: 0.4984 - acc: 0.8278 - val_loss: 0.5872 - val_acc: 0.7833\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.5014 - acc: 0.8296 - val_loss: 0.6141 - val_acc: 0.7750\n",
      "Epoch 61/100\n",
      "1080/1080 [==============================] - 0s 268us/step - loss: 0.4905 - acc: 0.8250 - val_loss: 0.5887 - val_acc: 0.7583\n",
      "Epoch 62/100\n",
      "1080/1080 [==============================] - 0s 255us/step - loss: 0.4726 - acc: 0.8472 - val_loss: 0.5910 - val_acc: 0.7750\n",
      "Epoch 63/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.4741 - acc: 0.8315 - val_loss: 0.5777 - val_acc: 0.7917\n",
      "Epoch 64/100\n",
      "1080/1080 [==============================] - 0s 258us/step - loss: 0.4706 - acc: 0.8380 - val_loss: 0.5818 - val_acc: 0.7750\n",
      "Epoch 65/100\n",
      "1080/1080 [==============================] - 0s 257us/step - loss: 0.4688 - acc: 0.8361 - val_loss: 0.5967 - val_acc: 0.7500\n",
      "Epoch 66/100\n",
      "1080/1080 [==============================] - 0s 258us/step - loss: 0.4634 - acc: 0.8389 - val_loss: 0.5518 - val_acc: 0.8167\n",
      "Epoch 67/100\n",
      "1080/1080 [==============================] - 0s 268us/step - loss: 0.4400 - acc: 0.8583 - val_loss: 0.5333 - val_acc: 0.8083\n",
      "Epoch 68/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 0.4323 - acc: 0.8528 - val_loss: 0.5546 - val_acc: 0.8083\n",
      "Epoch 69/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.4516 - acc: 0.8463 - val_loss: 0.5450 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.4436 - acc: 0.8528 - val_loss: 0.5644 - val_acc: 0.7833\n",
      "Epoch 71/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.4185 - acc: 0.8556 - val_loss: 0.5342 - val_acc: 0.8167\n",
      "Epoch 72/100\n",
      "1080/1080 [==============================] - 0s 256us/step - loss: 0.4271 - acc: 0.8537 - val_loss: 0.5939 - val_acc: 0.7833\n",
      "Epoch 73/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.4306 - acc: 0.8509 - val_loss: 0.5397 - val_acc: 0.7833\n",
      "Epoch 74/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.4148 - acc: 0.8583 - val_loss: 0.5557 - val_acc: 0.7750\n",
      "Epoch 75/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.4167 - acc: 0.8602 - val_loss: 0.5247 - val_acc: 0.8167\n",
      "Epoch 76/100\n",
      "1080/1080 [==============================] - 0s 258us/step - loss: 0.4181 - acc: 0.8556 - val_loss: 0.5512 - val_acc: 0.7750\n",
      "Epoch 77/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.4049 - acc: 0.8667 - val_loss: 0.5116 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "1080/1080 [==============================] - 0s 255us/step - loss: 0.4058 - acc: 0.8648 - val_loss: 0.4956 - val_acc: 0.8167\n",
      "Epoch 79/100\n",
      "1080/1080 [==============================] - 0s 269us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.5233 - val_acc: 0.7750\n",
      "Epoch 80/100\n",
      "1080/1080 [==============================] - 0s 259us/step - loss: 0.3791 - acc: 0.8824 - val_loss: 0.5077 - val_acc: 0.8167\n",
      "Epoch 81/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.4047 - acc: 0.8694 - val_loss: 0.5932 - val_acc: 0.7667\n",
      "Epoch 82/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.3924 - acc: 0.8676 - val_loss: 0.5346 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.3706 - acc: 0.8796 - val_loss: 0.5194 - val_acc: 0.8083\n",
      "Epoch 84/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 0.3680 - acc: 0.8787 - val_loss: 0.4975 - val_acc: 0.8333\n",
      "Epoch 85/100\n",
      "1080/1080 [==============================] - 0s 258us/step - loss: 0.4049 - acc: 0.8491 - val_loss: 0.5441 - val_acc: 0.7833\n",
      "Epoch 86/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.3939 - acc: 0.8657 - val_loss: 0.4951 - val_acc: 0.8333\n",
      "Epoch 87/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 0.3703 - acc: 0.8769 - val_loss: 0.5431 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "1080/1080 [==============================] - 0s 257us/step - loss: 0.3574 - acc: 0.8861 - val_loss: 0.5174 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "1080/1080 [==============================] - 0s 264us/step - loss: 0.3642 - acc: 0.8815 - val_loss: 0.4714 - val_acc: 0.8250\n",
      "Epoch 90/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.3389 - acc: 0.8870 - val_loss: 0.4782 - val_acc: 0.8250\n",
      "Epoch 91/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.3504 - acc: 0.8870 - val_loss: 0.5777 - val_acc: 0.7583\n",
      "Epoch 92/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.3655 - acc: 0.8741 - val_loss: 0.5431 - val_acc: 0.8167\n",
      "Epoch 93/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.3426 - acc: 0.8880 - val_loss: 0.4926 - val_acc: 0.8083\n",
      "Epoch 94/100\n",
      "1080/1080 [==============================] - 0s 257us/step - loss: 0.3521 - acc: 0.8778 - val_loss: 0.4523 - val_acc: 0.8500\n",
      "Epoch 95/100\n",
      "1080/1080 [==============================] - 0s 263us/step - loss: 0.3406 - acc: 0.8824 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "1080/1080 [==============================] - 0s 260us/step - loss: 0.3426 - acc: 0.8889 - val_loss: 0.4997 - val_acc: 0.8250\n",
      "Epoch 97/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.3370 - acc: 0.8972 - val_loss: 0.4965 - val_acc: 0.8167\n",
      "Epoch 98/100\n",
      "1080/1080 [==============================] - 0s 262us/step - loss: 0.3415 - acc: 0.8870 - val_loss: 0.4945 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "1080/1080 [==============================] - 0s 261us/step - loss: 0.3302 - acc: 0.8880 - val_loss: 0.4822 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "1080/1080 [==============================] - 0s 272us/step - loss: 0.3333 - acc: 0.8944 - val_loss: 0.4934 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "fit = convnet(X_train, Y_train,X_test, Y_test, epoch = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**: although it may not match perfectly, your expected output should be close to ours and your cost value should decrease.\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "    <td> \n",
    "    **Train Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.8917\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    **Test Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.0.8250\n",
    "    </td> \n",
    "</tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show your model layers and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 8)         392       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          528       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,310\n",
      "Trainable params: 1,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fit.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

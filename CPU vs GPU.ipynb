{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU vs GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed difference of CPU and GPU can be significant in deep learning. But how much? Letâ€™s do a test.\n",
    "\n",
    "The original source code was from https://medium.com/@erikhallstrm/hello-world-tensorflow-649b15aed18c, with some modifications by @faizmisman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blogs.nvidia.com/wp-content/uploads/2009/12/6a00d834515fca69e201287663224d970c.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing some necessary libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code below is to show lists of CPU and GPU running on your machine.\n",
    "\n",
    "NOTE: You can see \"/device:CPU:0\" and \"/device:GPU:0\" on the output if your tensorflow is running on both CPU and GPU. If you have multiple GPUs running, the list should be \"/device:GPU:0\", \"/device:GPU:1\" and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function below is to create the random matrix r1 and r2 and run dot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_times():\n",
    "\n",
    "    device_times = {\n",
    "        \"/gpu:0\":[],\n",
    "        \"/cpu:0\":[]\n",
    "    }\n",
    "    matrix_sizes = range(1000,6000,1000) # range of matrix sizes with range(initial_size, end_size, interval)\n",
    "\n",
    "    for size in matrix_sizes:\n",
    "        for device_name in device_times.keys():\n",
    "            \n",
    "            shape = (size,size)\n",
    "            print(\"####### Calculating on the \" + device_name + \" with matrix size \" + str(size) + \" #######\")\n",
    "            data_type = tf.float16\n",
    "            with tf.device(device_name):\n",
    "                r1 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type) # Generating random value matrix for r1\n",
    "                r2 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type) # Generating random value matrix for r2\n",
    "                dot_operation = tf.matmul(r2, r1) # Performing dot product on matrix r1 and r2\n",
    "\n",
    "\n",
    "            with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "                    start_time = time.time()\n",
    "                    result = session.run(dot_operation)\n",
    "                    time_taken = time.time() - start_time\n",
    "                    device_times[device_name].append(time_taken)\n",
    "                    print(\"Time taken: \" + str(time_taken))\n",
    "            #print(device_times)\n",
    "\n",
    "            #if time_taken > maximum_time:\n",
    "    return device_times, matrix_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check how long it take for the the CPU and the GPU to run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_times, matrix_sizes = get_times()\n",
    "gpu_times = device_times[\"/gpu:0\"]\n",
    "cpu_times = device_times[\"/cpu:0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(matrix_sizes[:len(gpu_times)], gpu_times, 'o-', label = 'GPU')\n",
    "plt.plot(matrix_sizes[:len(cpu_times)], cpu_times, 'o-', label = 'CPU')\n",
    "plt.ylabel('Time(s)')\n",
    "plt.xlabel('Matrix size')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Transfer Learning?\n",
    "\n",
    "A machine learning method where a model developed for a task is reused as the starting point for a model on a second task.\n",
    "\n",
    "\n",
    "### Why Transfer Learning?\n",
    "\n",
    "- In practice a very few people train a Convolution network from scratch (random initialisation) because it is rare to get  enough dataset. So, using pre-trained network weights as initialisations or a fixed feature extractor helps in solving most of the problems in hand.\n",
    "\n",
    "\n",
    "- Very Deep Networks are expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.\n",
    "\n",
    "\n",
    "- Determining the topology/flavour/training method/hyper parameters for deep learning is a black art with not much theory to guide you.\n",
    "\n",
    "\n",
    "### How Transfer Learning helps ?\n",
    "\n",
    "When you look at what these Deep Learning networks learn (Figure below), they try to detect edges in the earlier layers, Shapes in the middle layer and some high level data specific features in the later layers. These trained networks are generally helpful in solving other computer vision problems. If you have another different set of image, it will be good if just using the pre-trained weights rather than you trainyour architecture from scratch.\n",
    "\n",
    "<img src = \"https://cdn-images-1.medium.com/max/1000/1*L8NWufrce1Bt9aDIN7Tu4A.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets have a look at how to do transfer learning using Keras and various cases in Transfer learning.\n",
    "\n",
    "Starting with include important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "\n",
    "In this excercise, we use cats vs dogs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'catdog'\n",
    "\n",
    "filename_path = os.getcwd() + '\\\\' + dataset_folder;\n",
    "\n",
    "model_train = filename_path + '\\\\train\\\\'  \n",
    "model_val = filename_path + '\\\\val\\\\'\n",
    "model_test = filename_path + '\\\\test\\\\'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "##Creating Training set\n",
    "training_set = train_datagen.flow_from_directory(directory = model_train, # train dataset directory\n",
    "                                                 color_mode = 'rgb',      # Since we use color picture, set to 'rgb' or 'gray' for gray picture\n",
    "                                                 target_size = (240, 240),# rescaling the picture size to 240pix x 240pix\n",
    "                                                 batch_size = 64, \n",
    "                                                 shuffle=False, \n",
    "                                                 class_mode = 'binary')   # Since there are only cats and dogs class. We set it to binary\n",
    "\n",
    "\n",
    "##Creating Validation set\n",
    "valid_set = valid_datagen.flow_from_directory(directory = model_val,\n",
    "                                             color_mode = 'rgb',\n",
    "                                             target_size = (240, 240),\n",
    "                                             shuffle=False, \n",
    "                                             batch_size = 64,\n",
    "                                             class_mode = 'binary')\n",
    "\n",
    "\n",
    "##Creating Test set\n",
    "test_set = test_datagen.flow_from_directory(directory=model_test,\n",
    "                                            target_size=(240, 240),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            batch_size=1,\n",
    "                                            class_mode=None, #Since in the test folder only have 1 class\n",
    "                                            shuffle=False,\n",
    "                                            seed=42 )\n",
    "\n",
    "\n",
    "print(training_set.class_indices)\n",
    "print(len(training_set))\n",
    "valid_set.n\n",
    "valid_set.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 240, 240\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 5000\n",
    "batch_size = 16\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Transfer learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For the first step, call a library for the specific architecture (in this case is VGG16). For more information on lists of available architecture on Keras, click [HERE](https://keras.io/applications/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16 # in this excercise we are going to use VGG16 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, call the model and show summary of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is to determine which layers on the VGG16 to be freeze. That means, the weight on the freeze layer will not be trained again.\n",
    "\n",
    "There are **two** conditions whether to freeze or train the whole network again\n",
    "\n",
    "### 1 - New dataset is small and similar to original dataset:\n",
    "\n",
    "There is a problem of over-fitting, if we try to train the entire network. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n",
    "\n",
    "<img src = \"img/freeze.jpg\">\n",
    "\n",
    "### 2 - New dataset is large and similar to the original dataset\n",
    "\n",
    "Since we have more data, we can have more confidence that we wonâ€™t overfit if we were to try to fine-tune through the full network.\n",
    "\n",
    "<img src = \"img/nf.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets model that need to be fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = Model(input = model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=training_set.n // training_set.batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=valid_set,\n",
    "        validation_steps=valid_set.n // valid_set.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**: your expected output should be close to ours and your lost value should decrease, and it should be better than previous excercise.\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "    <td> \n",
    "    **Train Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.8501\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    **Test Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.8814\n",
    "    </td> \n",
    "</tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "- https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8\n",
    "- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

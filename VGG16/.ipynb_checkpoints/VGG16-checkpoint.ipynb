{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise - Build VGG16 architecture with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Only if you want to run with CPU\n",
    "\n",
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing impotant library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPooling2D, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Loading Dataset using *ImageDataGenerator* and *flow_from_directory*\n",
    "\n",
    "\n",
    "Keras is a great high level library which allows anyone to create powerful machine learning models in minutes.\n",
    "\n",
    "Keras has this ImageDataGenerator class which allows the users to to perform image augmentation on the fly in a very easy way. You can read about that in [Keras’s official documentation](https://keras.io/preprocessing/image) and the tutorial [Here.](https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720)\n",
    "\n",
    "Download the <b>train dataset</b> and <b>test dataset</b>, extract them into 2 different folders named as <b>“train”</b> and <b>“test”</b>. The train folder should contain *‘n’* folders each containing images of respective classes. For example,In the Dog vs Cats data set,the train folder should have 2 folders,namely “Dog” and “Cats” containing respective images inside them.\n",
    "\n",
    "Create a <b>validation set</b>,often you have to manually create a validation data by sampling images from the train folder (you can either sample randomly or in the order your problem needs the data to be fed) and moving them to a new folder named “valid”. If validation set is already provided, you could use them instead of creating them manually.\n",
    "\n",
    "the <b>test folder</b> also should contain a <b>single folder</b> inside which all the test images are present,this is there because the flow_from_directory() expects at least one directory under the given directory path.\n",
    "\n",
    "The folder names for the classes are important,name(or rename) them with respective label names,so that it would easy for you later.\n",
    "\n",
    "### See image below for better understanding\n",
    "\n",
    "<img src = \"https://cdn-images-1.medium.com/max/800/1*HpvpA9pBJXKxaPCl5tKnLg.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cats vs dogs dataset also can be downloaded at https://www.kaggle.com/c/dogs-vs-cats/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'catdog'\n",
    "\n",
    "filename_path = os.getcwd() + '\\\\' + dataset_folder;\n",
    "\n",
    "model_train = filename_path + '\\\\train\\\\'  \n",
    "model_val = filename_path + '\\\\val\\\\'\n",
    "model_test = filename_path + '\\\\test\\\\'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "##Creating Training set\n",
    "training_set = train_datagen.flow_from_directory(directory = model_train, # train dataset directory\n",
    "                                                 color_mode = 'rgb',      # Since we use color picture, set to 'rgb' or 'gray' for gray picture\n",
    "                                                 target_size = (240, 240),# rescaling the picture size to 240pix x 240pix\n",
    "                                                 batch_size = 64, \n",
    "                                                 shuffle=False, \n",
    "                                                 class_mode = 'binary')   # Since there are only cats and dogs class. We set it to binary\n",
    "\n",
    "\n",
    "##Creating Validation set\n",
    "valid_set = valid_datagen.flow_from_directory(directory = model_val,\n",
    "                                             color_mode = 'rgb',\n",
    "                                             target_size = (240, 240),\n",
    "                                             shuffle=False, \n",
    "                                             batch_size = 64,\n",
    "                                             class_mode = 'binary')\n",
    "\n",
    "\n",
    "##Creating Test set\n",
    "test_set = test_datagen.flow_from_directory(directory=model_test,\n",
    "                                            target_size=(240, 240),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            batch_size=1,\n",
    "                                            class_mode=None, #Since in the test folder only have 1 class\n",
    "                                            shuffle=False,\n",
    "                                            seed=42 )\n",
    "\n",
    "\n",
    "print(training_set.class_indices)\n",
    "print(len(training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgX, Y = next(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,2):\n",
    "    img = imgX[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.hist(img[:,:,0].flatten(), bins=100, normed=True, color='r')\n",
    "    plt.hist(img[:,:,1].flatten(), bins=100, normed=True, color='g')\n",
    "    plt.hist(img[:,:,2].flatten(), bins=100, normed=True, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = imgX[0]\n",
    "test_img.shape\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Building VGG16 model\n",
    "\n",
    "VGG-16 is a simpler architecture model, since its not using much hyper parameters. It always uses <b>3 x 3 filters</b> with <b>stride of 1</b> in convolution layer and uses <b>SAME padding</b> in <b>pooling layers 2 x 2 with stride of 2.</b> But, Number of filters are <b>different</b> for every Convolutional layer.\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "    <td> \n",
    "    <b>Layer</b>\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "    <b>No. of filter</b>\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    1\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      64\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    2\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      128\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    3\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      256\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    4\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      512\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    5\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      512\n",
    "    </td> \n",
    "</tr> \n",
    "</table>\n",
    "\n",
    "\n",
    "### Your task now is to build a VGG16 architecture model as shown in the picture below:\n",
    "\n",
    "<img src = \"img/vgg16.jpg\" >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "# Adding the 1st convolutional layer\n",
    "model.add(Conv2D(8, (3, 3), input_shape = (240, 240, 3), padding='same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(8, (3, 3), padding='same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides=2, padding='same'))\n",
    "\n",
    "\n",
    "# Adding a 2nd convolutional layer\n",
    "### START CODE HERE ### (≈5 lines)\n",
    "None\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Adding a 3rd convolutional layer\n",
    "### START CODE HERE ### (≈7 lines)\n",
    "None\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Adding a 4th convolutional layer\n",
    "### START CODE HERE ### (≈7 lines)\n",
    "None\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Adding a 5th convolutional layer\n",
    "### START CODE HERE ### (≈7 lines)\n",
    "None\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Flattening\n",
    "### START CODE HERE ### (≈1 line)\n",
    "None\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Full connection\n",
    "### START CODE HERE ### (≈3 lines)\n",
    "None # This Dense layer should have 1024 output and relu function\n",
    "None # This Dense layer should have 1024 output and relu function\n",
    "None # This Dense layer should have 1 output and sigmoid function\n",
    "### END CODE HERE ###\n",
    "\n",
    "#compiling model\n",
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your model should look like this!\n",
    "\n",
    "<img src = \"img/summary.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's run theVGG16!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=training_set.n // training_set.batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=valid_set,\n",
    "        validation_steps=valid_set.n // valid_set.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.reset()\n",
    "pred=model.predict_generator(test_set,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done guys! now you successfully build your own deep learning architecture..\n",
    "\n",
    "<img src = \"img/a3e.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
